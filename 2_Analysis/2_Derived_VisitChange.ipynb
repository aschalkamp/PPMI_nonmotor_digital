{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/c.c21013066/docker/envs/timeseries/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "import re\n",
    "\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv('/scratch/c.c21013066/data/ppmi/phenotypes2021/demographics_clean.csv',parse_dates=['date_diagnosis'])\n",
    "grouped_mean = pd.read_csv('/scratch/c.c21013066/data/ppmi/accelerometer/weekly_mean.csv',parse_dates=['date_y'])\n",
    "grouped_mean = pd.merge(demo,grouped_mean,on='participant',how='right')\n",
    "grouped_mean = grouped_mean[grouped_mean['diagnosis']=='pd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean['time_since_diagnosis'] = (grouped_mean['date_y'] -grouped_mean['date_diagnosis'])/np.timedelta64(1,'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    85.000000\n",
      "mean      6.813910\n",
      "std       2.107513\n",
      "min       2.499709\n",
      "25%       4.999418\n",
      "50%       7.165103\n",
      "75%       8.413588\n",
      "max      11.666222\n",
      "Name: time_since_diagnosis, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    85.000000\n",
       "mean     67.688599\n",
       "std       7.543153\n",
       "min      46.245987\n",
       "25%      62.752829\n",
       "50%      68.420296\n",
       "75%      73.249964\n",
       "max      89.918342\n",
       "Name: visit_age, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grouped_mean.groupby('participant').last()['time_since_diagnosis'].describe())\n",
    "grouped_mean.groupby('participant').last()['visit_age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many have more than 1 visit?\n",
    "n_visits = grouped_mean.groupby('participant').size().rename('size')\n",
    "grouped_mean = pd.merge(n_visits,grouped_mean,on='participant',how='outer')\n",
    "grouped_mean = grouped_mean[grouped_mean['size']>1]\n",
    "n_visits.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsychiatric = ['stai_trait','stai_state','gds','quip']\n",
    "cognition = ['semantic_fluency','moca','benton','lns','hvlt_recall','hvlt_recognition','hvlt_retention','symbol_digit']\n",
    "autonome = ['epworth','rbd','systolic_bp_drop','scopa_aut']\n",
    "daily = ['se_adl','updrs_i']\n",
    "motor = ['updrs_ii','updrs_iii_OFF']\n",
    "medication = ['updrs_iii_ON','updrs_iv','LEDD',]\n",
    "features = np.hstack([cognition,neuropsychiatric,autonome,daily,motor,medication])\n",
    "covs = ['visit_age','date_y']\n",
    "predictors = grouped_mean.filter(regex='(walking|step|efficiency|total_sleep|pulse|deep|light|rem|nrem|rmssd|wake)').columns\n",
    "sleep_col = grouped_mean.filter(regex='(efficiency|total_sleep|deep|light|rem|nrem|wake)').columns\n",
    "phys = grouped_mean.filter(regex='(walking|step)').columns\n",
    "vital = grouped_mean.filter(regex='(pulse|rmssd)').columns\n",
    "predictors_filt = [a for a in predictors if not re.search('_ms', a)]\n",
    "sleep_col = [a for a in sleep_col if not re.search('_ms', a)]\n",
    "phys = [a for a in phys if not re.search('_ms', a)]\n",
    "vital = [a for a in vital if not re.search('_ms', a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity to detect change\n",
    "cohen's d between first and second visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_visit = grouped_mean.groupby('participant').first()\n",
    "second_visit = grouped_mean.groupby('participant').nth(1)\n",
    "\n",
    "visit_diff = first_visit[np.hstack([features,predictors_filt])] - second_visit[np.hstack([features,predictors_filt])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean     0.629484\n",
       "std      0.222128\n",
       "size    35.000000\n",
       "Name: date_y, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((second_visit['date_y'] - first_visit['date_y'])/np.timedelta64(1,'Y')).agg(['mean','std','size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean    5.546843\n",
       "std     2.314049\n",
       "Name: time_since_diagnosis, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_visit['time_since_diagnosis'].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen = pd.DataFrame(columns=['T', 'dof', 'alternative', 'p-val', 'CI95%', 'cohen-d', 'BF10', 'power','hedges g','cohen'],index=np.hstack([features,predictors_filt]))\n",
    "for test in np.hstack([features,predictors_filt]):\n",
    "    cohen.loc[test,['T', 'dof', 'alternative', 'p-val', 'CI95%', 'cohen-d', 'BF10', 'power']] = pg.ttest(second_visit[test],first_visit[test],correction=False,paired=True).values\n",
    "    cohen.loc[test,['hedges g']] = np.abs(pg.compute_effsize(first_visit[test],second_visit[test],paired=True,eftype='hedges'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen = cohen.reset_index()\n",
    "cohen['category'] = cohen['index'].apply(lambda x: 'digital' if x in predictors_filt else 'clinical')\n",
    "cohen['cohen-d'] = cohen['cohen-d'].astype(float)\n",
    "cohen['hedges g'] = cohen['hedges g'].astype(float)\n",
    "cohen = cohen.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           cohen-d  hedges g\n",
      "category                    \n",
      "clinical  0.129012  0.127059\n",
      "digital   0.246596  0.240368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_176695/2512666005.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(cohen.groupby('category').mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-test</th>\n",
       "      <td>-2.78894</td>\n",
       "      <td>35</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>[-0.2, -0.03]</td>\n",
       "      <td>0.945392</td>\n",
       "      <td>5.665</td>\n",
       "      <td>0.773898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\n",
       "T-test -2.78894   35   two-sided  0.008496  [-0.2, -0.03]  0.945392  5.665   \n",
       "\n",
       "           power  \n",
       "T-test  0.773898  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cohen.groupby('category').mean())\n",
    "pg.ttest(cohen.loc[cohen['category']=='clinical',\"cohen-d\"],cohen.loc[cohen['category']=='digital',\"cohen-d\"],correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen.to_csv('/scratch/c.c21013066/data/ppmi/analyses/studywatch/visit12_difference_cohen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associations of change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sum_walking_minutes_diff  visit_age_diff date_y_diff\n",
      "1                         NaN             NaN         NaT\n",
      "2                    0.000000        0.837800    306 days\n",
      "8                         NaN             NaN         NaT\n",
      "9                    0.888889        0.919937    336 days\n",
      "11                        NaN             NaN         NaT\n",
      "..                        ...             ...         ...\n",
      "128                       NaN             NaN         NaT\n",
      "129                 -2.197040        0.501037    183 days\n",
      "130                       NaN             NaN         NaT\n",
      "131                 -0.706633        0.503775    184 days\n",
      "132                 -0.833333        1.002074    366 days\n",
      "\n",
      "[84 rows x 3 columns]\n",
      "     sum_walking_minutes_diff  visit_age_diff date_y_diff\n",
      "1                         NaN             NaN         NaT\n",
      "2                    0.000000        0.837800    306 days\n",
      "8                         NaN             NaN         NaT\n",
      "9                    0.966250        0.919937    336 days\n",
      "11                        NaN             NaN         NaT\n",
      "..                        ...             ...         ...\n",
      "128                       NaN             NaN         NaT\n",
      "129                 -4.384985        0.501037    183 days\n",
      "130                       NaN             NaN         NaT\n",
      "131                 -1.402675        0.503775    184 days\n",
      "132                 -0.831609        1.002074    366 days\n",
      "\n",
      "[84 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# compute difference between visits\n",
    "diff = grouped_mean.groupby('participant')[np.hstack([features,predictors_filt,covs])].diff()\n",
    "grouped_mean[[f'{name}_diff' for name in np.hstack([features,predictors_filt,covs])]] = diff\n",
    "# scale by time_diff\n",
    "grouped_mean[[f'{name}_diff' for name in np.hstack([features,predictors_filt])]] = grouped_mean[[f'{name}_diff' for name in np.hstack([features,predictors_filt])]].div(grouped_mean['visit_age_diff'],\n",
    "axis=0)\n",
    "# average over visits\n",
    "diff_mean = grouped_mean.groupby('participant').mean()#nth(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_names = ['Semantic Fluency', 'MOCA', 'Benton',\n",
    "       'Letter Number Sequencing', 'HVLT Recall', 'HVLT Recognition', 'HVLT Retention',\n",
    "       'Symbol Digit', 'STAI trait', 'STAI state', 'GDS', 'QUIP',\n",
    "       'ESS', 'RBDSQ', 'Systolic BP Drop', 'SCOPA autonome',\n",
    "       'Schwab England ADL', 'UPDRS I','UPDRS II','UPDRS III OFF','UPDRS III ON','UPDRS IV', 'LEDD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Fluency sleep_efficiency\n",
      "Semantic Fluency num_awakenings\n",
      "Semantic Fluency total_sleep_time_hour\n",
      "Semantic Fluency wake_after_sleep_onset_hour\n",
      "Semantic Fluency total_nrem_time_hour\n",
      "Semantic Fluency total_rem_time_hour\n",
      "Semantic Fluency total_deep_nrem_time_hour\n",
      "Semantic Fluency total_light_nrem_time_hour\n",
      "MOCA sleep_efficiency\n",
      "MOCA num_awakenings\n",
      "MOCA total_sleep_time_hour\n",
      "MOCA wake_after_sleep_onset_hour\n",
      "MOCA total_nrem_time_hour\n",
      "MOCA total_rem_time_hour\n",
      "MOCA total_deep_nrem_time_hour\n",
      "MOCA total_light_nrem_time_hour\n",
      "Benton sleep_efficiency\n",
      "Benton num_awakenings\n",
      "Benton total_sleep_time_hour\n",
      "Benton wake_after_sleep_onset_hour\n",
      "Benton total_nrem_time_hour\n",
      "Benton total_rem_time_hour\n",
      "Benton total_deep_nrem_time_hour\n",
      "Benton total_light_nrem_time_hour\n",
      "Letter Number Sequencing sleep_efficiency\n",
      "Letter Number Sequencing num_awakenings\n",
      "Letter Number Sequencing total_sleep_time_hour\n",
      "Letter Number Sequencing wake_after_sleep_onset_hour\n",
      "Letter Number Sequencing total_nrem_time_hour\n",
      "Letter Number Sequencing total_rem_time_hour\n",
      "Letter Number Sequencing total_deep_nrem_time_hour\n",
      "Letter Number Sequencing total_light_nrem_time_hour\n",
      "HVLT Recall sleep_efficiency\n",
      "HVLT Recall num_awakenings\n",
      "HVLT Recall total_sleep_time_hour\n",
      "HVLT Recall wake_after_sleep_onset_hour\n",
      "HVLT Recall total_nrem_time_hour\n",
      "HVLT Recall total_rem_time_hour\n",
      "HVLT Recall total_deep_nrem_time_hour\n",
      "HVLT Recall total_light_nrem_time_hour\n",
      "HVLT Recognition sleep_efficiency\n",
      "HVLT Recognition num_awakenings\n",
      "HVLT Recognition total_sleep_time_hour\n",
      "HVLT Recognition wake_after_sleep_onset_hour\n",
      "HVLT Recognition total_nrem_time_hour\n",
      "HVLT Recognition total_rem_time_hour\n",
      "HVLT Recognition total_deep_nrem_time_hour\n",
      "HVLT Recognition total_light_nrem_time_hour\n",
      "HVLT Retention sleep_efficiency\n",
      "HVLT Retention num_awakenings\n",
      "HVLT Retention total_sleep_time_hour\n",
      "HVLT Retention wake_after_sleep_onset_hour\n",
      "HVLT Retention total_nrem_time_hour\n",
      "HVLT Retention total_rem_time_hour\n",
      "HVLT Retention total_deep_nrem_time_hour\n",
      "HVLT Retention total_light_nrem_time_hour\n",
      "Symbol Digit sleep_efficiency\n",
      "Symbol Digit num_awakenings\n",
      "Symbol Digit total_sleep_time_hour\n",
      "Symbol Digit wake_after_sleep_onset_hour\n",
      "Symbol Digit total_nrem_time_hour\n",
      "Symbol Digit total_rem_time_hour\n",
      "Symbol Digit total_deep_nrem_time_hour\n",
      "Symbol Digit total_light_nrem_time_hour\n",
      "UPDRS III OFF sleep_efficiency\n",
      "UPDRS III OFF num_awakenings\n",
      "UPDRS III OFF total_sleep_time_hour\n",
      "UPDRS III OFF wake_after_sleep_onset_hour\n",
      "UPDRS III OFF total_nrem_time_hour\n",
      "UPDRS III OFF total_rem_time_hour\n",
      "UPDRS III OFF total_deep_nrem_time_hour\n",
      "UPDRS III OFF total_light_nrem_time_hour\n"
     ]
    }
   ],
   "source": [
    "corr = pd.DataFrame(columns=['N','pearson r','p-value'],index=pd.MultiIndex.from_product([np.hstack([cl_names,predictors_filt]),\n",
    "                                                                                          np.hstack([cl_names,predictors_filt])],\n",
    "                                                                                         names=['f1','f2']))\n",
    "for (i,p),m in zip(enumerate([f'{name}_diff' for name in np.hstack([features,predictors_filt])]),\n",
    "                               np.hstack([cl_names,predictors_filt])):\n",
    "    for (j,u),n in zip(enumerate([f'{name}_diff' for name in np.hstack([features,predictors_filt])]),\n",
    "                               np.hstack([cl_names,predictors_filt])):\n",
    "        if j>i:\n",
    "            try:\n",
    "                dat = diff_mean.dropna(subset=[p,u])\n",
    "                corr.loc[(m,n),'N'] = dat.shape[0]\n",
    "                r,pval = stats.pearsonr(dat[p],dat[u])\n",
    "                corr.loc[(m,n),'pearson r'] = r\n",
    "                corr.loc[(m,n),'p-value'] = pval\n",
    "            except:\n",
    "                print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.to_csv('/scratch/c.c21013066/data/ppmi/analyses/studywatch/ratechange__month_mean_corr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
